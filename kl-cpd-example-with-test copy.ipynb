{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from utils import datasets, kl_cpd, models, metrics\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal sampling is impossible, do random sampling.\n"
     ]
    }
   ],
   "source": [
    "experiments_name = 'explosion'\n",
    "train_dataset, test_dataset = datasets.CPDDatasets(experiments_name=experiments_name).get_dataset_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "args['wnd_dim'] = 4\n",
    "args['RNN_hid_dim'] = 16\n",
    "args['batch_size'] = 8\n",
    "args['lr'] = 1e-4\n",
    "args['weight_decay'] = 0.\n",
    "args['grad_clip'] = 10\n",
    "args['CRITIC_ITERS'] = 5\n",
    "args['weight_clip'] = .1\n",
    "args['lambda_ae'] = 0.1 #0.001\n",
    "args['lambda_real'] = 10 #0.1\n",
    "args['num_layers'] = 1\n",
    "args['data_dim'] = 12288\n",
    "args['emb_dim'] = 100\n",
    "\n",
    "args['window_1'] = 4\n",
    "args['window_2'] = 4\n",
    "\n",
    "args['sqdist'] = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/eromanenkova/.cache/torch/hub/facebookresearch_pytorchvideo_main\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | netG      | NetG       | 1.4 M \n",
      "1 | netD      | NetD       | 2.5 M \n",
      "2 | extractor | Sequential | 2.0 M \n",
      "-----------------------------------------\n",
      "4.0 M     Trainable params\n",
      "2.0 M     Non-trainable params\n",
      "6.0 M     Total params\n",
      "23.865    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d3661a1f7f425697928dfc1e9a13f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fc167c66700>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eromanenkova/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/eromanenkova/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1316, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/eromanenkova/anaconda3/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fc167c66700><function _MultiProcessingDataLoaderIter.__del__ at 0x7fc167c66700>\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eromanenkova/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "  File \"/home/eromanenkova/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "        self._shutdown_workers()self._shutdown_workers()\n",
      "\n",
      "  File \"/home/eromanenkova/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1316, in _shutdown_workers\n",
      "  File \"/home/eromanenkova/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1316, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/eromanenkova/anaconda3/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "    if w.is_alive():\n",
      "  File \"/home/eromanenkova/anaconda3/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fc167c66700>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eromanenkova/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/eromanenkova/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1316, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/eromanenkova/anaconda3/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 192, 4, 8, 8])\n",
      "torch.Size([8, 192, 4, 8, 8])\n",
      "torch.Size([8, 192, 4, 8, 8])\n",
      "torch.Size([8, 192, 4, 8, 8])\n",
      "torch.Size([8, 192, 4, 8, 8])\n",
      "torch.Size([8, 192, 4, 8, 8])\n",
      "torch.Size([8, 192, 4, 8, 8])\n",
      "torch.Size([8, 192, 4, 8, 8])\n",
      "torch.Size([8, 192, 4, 8, 8])\n",
      "torch.Size([8, 192, 4, 8, 8])\n",
      "torch.Size([8, 192, 4, 8, 8])\n",
      "torch.Size([8, 192, 4, 8, 8])\n",
      "torch.Size([8, 192, 4, 8, 8])\n",
      "torch.Size([8, 192, 4, 8, 8])\n",
      "torch.Size([8, 192, 4, 8, 8])\n",
      "torch.Size([8, 192, 4, 8, 8])\n",
      "torch.Size([8, 192, 4, 8, 8])\n",
      "torch.Size([8, 192, 4, 8, 8])\n",
      "torch.Size([8, 192, 4, 8, 8])\n",
      "torch.Size([8, 192, 4, 8, 8])\n",
      "torch.Size([8, 192, 4, 8, 8])\n",
      "torch.Size([8, 192, 4, 8, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                             | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name in ['x3d_m']:\n",
    "    extractor = torch.hub.load('facebookresearch/pytorchvideo:main', name, pretrained=True)\n",
    "    extractor = nn.Sequential(*list(extractor.blocks[:5]))\n",
    "    \n",
    "    seed = 0\n",
    "    models.fix_seeds(seed)\n",
    "    experiments_name = ('explosion')\n",
    "\n",
    "    netG = models.NetG(args)\n",
    "    netD = models.NetD(args)\n",
    "\n",
    "    kl_cpd_model = models.KLCPDVideo(netG, netD, args, train_dataset=train_dataset, test_dataset=test_dataset, \n",
    "                                     extractor=extractor)\n",
    "    \n",
    "    logger = TensorBoardLogger(save_dir='logs/explosion', name='kl_cpd')\n",
    "    \n",
    "    early_stop_callback = EarlyStopping(monitor=\"val_mmd2_real_D\", stopping_threshold=1e-5, \n",
    "                                        verbose=True, mode=\"min\", patience=5)\n",
    "\n",
    "    for param in kl_cpd_model.extractor.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=1,\n",
    "        gpus='1',\n",
    "        benchmark=True,\n",
    "        check_val_every_n_epoch=1,\n",
    "        gradient_clip_val=args['grad_clip'],\n",
    "        logger=logger,\n",
    "        callbacks=early_stop_callback\n",
    "    )\n",
    "\n",
    "    trainer.fit(kl_cpd_model)\n",
    "    torch.save(kl_cpd_model.state_dict(), 'model_' + name + '.pth')    \n",
    "    \n",
    "    threshold_number = 5\n",
    "    threshold_list = np.linspace(-5, 5, threshold_number)\n",
    "    threshold_list = 1 / (1 + np.exp(-threshold_list))\n",
    "    threshold_list = [-0.001] + list(threshold_list) + [1.001]\n",
    "    \n",
    "    \n",
    "    _, delay_list, fp_delay_list = metrics.evaluation_pipeline(kl_cpd_model, \n",
    "                                                           kl_cpd_model.val_dataloader(),  \n",
    "                                                           threshold_list, \n",
    "                                                           device='cuda', \n",
    "                                                           model_type='klcpd',\n",
    "                                                           verbose=False)    \n",
    "\n",
    "\n",
    "    path_to_saves = ''\n",
    "    metrics.write_metrics_to_file(path_to_saves + 'result_metrics.txt', _, name)    \n",
    "    \n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.plot(fp_delay_list.values(), delay_list.values(), '-o', markersize=8, label='TSCP')\n",
    "    plt.xlabel('Mean Time to False Alarm', fontsize=28)\n",
    "    plt.ylabel('Mean Detection Delay', fontsize=28)\n",
    "    plt.xticks(fontsize=24)\n",
    "    plt.yticks(fontsize=24)\n",
    "    plt.legend(loc='upper left', fontsize=26);        \n",
    "    plt.savefig('saves/figure_' + str(name) + '.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(kl_cpd_model.val_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_klcpd_output(kl_cpd_model, batch, window):\n",
    "    batch = batch.to(kl_cpd_model.device)\n",
    "    if len(batch.shape) <= 4:\n",
    "        seq_len = batch.shape[1]\n",
    "    else:\n",
    "        seq_len = batch.shape[2]\n",
    "\n",
    "    batch_history_slices, batch_future_slices = kl_cpd._history_future_separation_test(batch, window)\n",
    "    sigma_var = kl_cpd_model.sigma_var.to(kl_cpd_model.device)\n",
    "\n",
    "    pred_out = []\n",
    "    for i in range(len(batch_history_slices)):\n",
    "        zeros = torch.zeros(1, seq_len)\n",
    "\n",
    "        curr_history = kl_cpd_model.extractor(batch_history_slices[i]).transpose(1, 2).flatten(2)\n",
    "        curr_history, _ = kl_cpd_model.netD(curr_history.to(torch.float32))\n",
    "\n",
    "        curr_future = kl_cpd_model.extractor(batch_future_slices[i]).transpose(1, 2).flatten(2)\n",
    "        curr_future, _ = kl_cpd_model.netD(curr_future.to(torch.float32))\n",
    "\n",
    "        curr_history, curr_future = [Xi.reshape(*Xi.shape[:2], -1) for Xi in [curr_history, curr_future]]\n",
    "        mmd_scores = kl_cpd.batch_mmd2_loss(curr_history, curr_future, sigma_var)\n",
    "        zeros[:, 2 * window - 1:] = mmd_scores\n",
    "        pred_out.append(zeros)\n",
    "    pred_out = torch.cat(pred_out).to(kl_cpd_model.device)\n",
    "    po = pred_out\n",
    "    print(torch.tanh(po/torch.norm(po, p=3, dim=1, keepdim=True)))\n",
    "    print(torch.softmax(po/torch.max(po, dim=1, keepdim=True), dim=1))\n",
    "    # breakpoint()\n",
    "    #pred_out = pred_out / pred_out.max(1).values.expand(pred_out.shape[1], pred_out.shape[0]).transpose(0, 1)\n",
    "    #TODO check\n",
    "    #pred_out = torch.tanh(pred_out * 10 ** 7)\n",
    "    return pred_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1168, 0.0134,\n",
      "         0.0469, 0.7613, 0.0122, 0.0354, 0.0066, 0.0180, 0.0437],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0510, 0.0031,\n",
      "         0.0136, 0.0145, 0.7527, 0.0958, 0.0050, 0.2109, 0.3539],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1025, 0.4029,\n",
      "         0.4261, 0.0166, 0.1214, 0.0133, 0.1087, 0.3764, 0.7227],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0836, 0.3602,\n",
      "         0.2545, 0.0018, 0.0174, 0.6602, 0.6360, 0.0472, 0.1659],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2511, 0.1890,\n",
      "         0.0746, 0.6395, 0.2818, 0.0209, 0.0107, 0.6199, 0.4734],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5545, 0.0219,\n",
      "         0.2002, 0.0184, 0.5053, 0.5801, 0.3525, 0.3110, 0.5271],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0146, 0.0016,\n",
      "         0.0862, 0.7614, 0.0599, 0.0173, 0.0238, 0.0905, 0.0133],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0248, 0.1102,\n",
      "         0.1601, 0.7506, 0.3858, 0.1212, 0.0092, 0.0532, 0.0071]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward>)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'Tensor' and 'torch.return_types.max'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-edfdb3f83e81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# %%debug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpred_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_klcpd_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkl_cpd_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-40-2cca0ac1f30c>\u001b[0m in \u001b[0;36mget_klcpd_output\u001b[0;34m(kl_cpd_model, batch, window)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mpo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpo\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpo\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;31m# breakpoint()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m#pred_out = pred_out / pred_out.max(1).values.expand(pred_out.shape[1], pred_out.shape[0]).transpose(0, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'Tensor' and 'torch.return_types.max'"
     ]
    }
   ],
   "source": [
    "# %%debug\n",
    "pred_out = get_klcpd_output(kl_cpd_model, batch[0], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f57fccee670>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 2\n",
    "#plt.plot(pred_out[i].detach().cpu().numpy())\n",
    "#plt.plot(torch.tanh(pred_out[i] * 10 ** 5).detach().cpu().numpy())\n",
    "plt.plot(torch.log(pred_out[i]).detach().cpu().numpy())\n",
    "plt.plot((1 / (1 - 1 / pred_out[i])).detach().cpu().numpy())\n",
    "\n",
    "plt.plot(labels[i].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.7610e-06, 1.8587e-06, 3.3578e-06, 3.4813e-06, 1.6716e-06, 1.8619e-06,\n",
       "        3.7566e-06, 1.7263e-06], grad_fn=<MaxBackward0>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_out.max(1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.7610e-06, 4.7610e-06, 4.7610e-06, 4.7610e-06, 4.7610e-06, 4.7610e-06,\n",
       "         4.7610e-06, 4.7610e-06, 4.7610e-06, 4.7610e-06, 4.7610e-06, 4.7610e-06,\n",
       "         4.7610e-06, 4.7610e-06, 4.7610e-06, 4.7610e-06],\n",
       "        [1.8587e-06, 1.8587e-06, 1.8587e-06, 1.8587e-06, 1.8587e-06, 1.8587e-06,\n",
       "         1.8587e-06, 1.8587e-06, 1.8587e-06, 1.8587e-06, 1.8587e-06, 1.8587e-06,\n",
       "         1.8587e-06, 1.8587e-06, 1.8587e-06, 1.8587e-06],\n",
       "        [3.3578e-06, 3.3578e-06, 3.3578e-06, 3.3578e-06, 3.3578e-06, 3.3578e-06,\n",
       "         3.3578e-06, 3.3578e-06, 3.3578e-06, 3.3578e-06, 3.3578e-06, 3.3578e-06,\n",
       "         3.3578e-06, 3.3578e-06, 3.3578e-06, 3.3578e-06],\n",
       "        [3.4813e-06, 3.4813e-06, 3.4813e-06, 3.4813e-06, 3.4813e-06, 3.4813e-06,\n",
       "         3.4813e-06, 3.4813e-06, 3.4813e-06, 3.4813e-06, 3.4813e-06, 3.4813e-06,\n",
       "         3.4813e-06, 3.4813e-06, 3.4813e-06, 3.4813e-06],\n",
       "        [1.6716e-06, 1.6716e-06, 1.6716e-06, 1.6716e-06, 1.6716e-06, 1.6716e-06,\n",
       "         1.6716e-06, 1.6716e-06, 1.6716e-06, 1.6716e-06, 1.6716e-06, 1.6716e-06,\n",
       "         1.6716e-06, 1.6716e-06, 1.6716e-06, 1.6716e-06],\n",
       "        [1.8619e-06, 1.8619e-06, 1.8619e-06, 1.8619e-06, 1.8619e-06, 1.8619e-06,\n",
       "         1.8619e-06, 1.8619e-06, 1.8619e-06, 1.8619e-06, 1.8619e-06, 1.8619e-06,\n",
       "         1.8619e-06, 1.8619e-06, 1.8619e-06, 1.8619e-06],\n",
       "        [3.7566e-06, 3.7566e-06, 3.7566e-06, 3.7566e-06, 3.7566e-06, 3.7566e-06,\n",
       "         3.7566e-06, 3.7566e-06, 3.7566e-06, 3.7566e-06, 3.7566e-06, 3.7566e-06,\n",
       "         3.7566e-06, 3.7566e-06, 3.7566e-06, 3.7566e-06],\n",
       "        [1.7263e-06, 1.7263e-06, 1.7263e-06, 1.7263e-06, 1.7263e-06, 1.7263e-06,\n",
       "         1.7263e-06, 1.7263e-06, 1.7263e-06, 1.7263e-06, 1.7263e-06, 1.7263e-06,\n",
       "         1.7263e-06, 1.7263e-06, 1.7263e-06, 1.7263e-06]],\n",
       "       grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bfb2b8cf1499e33540bacdfc4dd76b4bb9572c0e18e6d28f6edc08a8ab91e54c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
