rnn_block_type: linear
data_dim: 12288
emb_dims: ${model.data_dim}
hidden_dims: 64
ranks_input: 1
ranks_output: 1
ranks_rnn: 1


model_name: linear_lstm

model_description: 
  input_block:
    _target_: src.models.tl_base_cells.CoreBlock
      block_type: identity
      input_dims: ${model.data_dim}
      hidden_dims: ${model.emb_dims}
      ranks: null # TODO
      bias_rank: ${model.ranks_input}
      normalize: both
      block_place: input

  rnn_block:
    _target_: torch.nn.LSTM
      input_dims: ${model.emb_dims}
      hidden_dims: ${model.hidden_dims}
      num_layers: 1
      bidirectional: False
      bias: ${model.ranks_rnn}
      batch_first: True
        
    output_block:
      _target_: src.models.tl_base_cells.CoreBlock
        block_type: linear
        input_dims: ${model.hidden_dims}
        hidden_dims: 1
        ranks: null
        bias_rank: ${model.ranks_output}
        normalize: in
        block_place: output
